import torchvision
from torchvision import transforms
import numpy as np
import torch
from torch import nn, optim
import matplotlib.pyplot as plt

from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method
from time import time

def train_model(model, x_train, x_test, y_train, y_test, epochs=15):
    transform = transforms.Compose([transforms.Normalize((0,), (1,)),])
    
    trainset = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train).type(torch.long))
    valset = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test).type(torch.long))
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
    valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)

    criterion = nn.NLLLoss()
    images, labels = next(iter(trainloader))
    images = images.view(images.shape[0], -1)
    labels = labels

    logps = model(images)
    loss = criterion(logps, labels)

    optimizer = optim.Adam(model.parameters(), lr=0.001)
    time0 = time()
    for e in range(epochs):
        running_loss = 0
        for images, labels in trainloader:

            images = images.view(images.shape[0], -1)
            labels = labels

            optimizer.zero_grad()

            output = model(images)
            loss = criterion(output, labels)

            loss.backward()

            optimizer.step()

            running_loss += loss.item()
        else:
            print("Epoch {} - Training loss: {}".format(e, running_loss/len(trainloader)))
    print("\nTraining Time (in minutes) =",(time()-time0)/60)


    images, labels = next(iter(valloader))

    img = images[0].view(1, 784)
    with torch.no_grad():
        logps = model(img)

    ps = torch.exp(logps)
    probab = list(ps.numpy()[0])
    print("Predicted Digit =", probab.index(max(probab)))
    view_classify(img.view(1, 28, 28), ps)

    correct_count, all_count = 0, 0
    for images,labels in valloader:
        for i in range(len(labels)):
            img = images[i].view(1, 784)
            with torch.no_grad():
                logps = model(img)


            ps = torch.exp(logps)
            probab = list(ps.numpy()[0])
            pred_label = probab.index(max(probab))
            true_label = labels.numpy()[i]
            if(true_label == pred_label):
                correct_count += 1
            all_count += 1

    print("Number Of Images Tested =", all_count)
    print("\nModel Accuracy =", (correct_count/all_count))
    
    return model

def eval_model(model, data, labels, high_conf_thres=None):
    """ Given a PyTorch model, ndarray of data points, and labels, prints model accuracy on the data.
        If a high_conf_thres is provided, it will be used as a threshold for what is considered a 
        "high confidence prediction" by the model. This will be used to report the proportion of 
        incorrectly classified samples for which the model had "high confidence" (class probability 
        greater than or equal to high_conf_thres)
    """
    correct_count, all_count, high_conf_misclassification_count = 0, 0, 0
    
    for i in range(len(data)):
        img = torch.from_numpy(data[i]).unsqueeze(axis=0) # Create tensor with batch dimension
        with torch.no_grad():
            logps = model(img)

        ps = torch.exp(logps)
        probab = list(ps.numpy()[0])
        pred_label = probab.index(max(probab))
        if (pred_label == labels[i]):
            correct_count += 1
        elif ((high_conf_thres != None) and (ps.max().item() >= high_conf_thres)):
            high_conf_misclassification_count += 1
        all_count += 1
    
    print("Number Of Samples Tested =", all_count)
    print("\nModel Accuracy =", (correct_count/all_count))
    if high_conf_thres != None:
        print("\nNumber of misclassified samples with high model confidence = ", (high_conf_misclassification_count))

def get_network_outputs(model, dataloader):
    """ Given a model and dataloader, returns an ndarray of the model outputs for data in the dataloader.
    """
    network_outputs = list()
    with torch.no_grad():
        for x, _ in dataloader:
            network_outputs.append(model(x))
            
    network_outputs = np.concatenate(network_outputs)
    
    return network_outputs

def add_adversarial_noise(model, dataloader, eps=3e-2):
    """ Returns an ndarray of adversarially perturbed versions of the data passed in with the dataloader, 
        generated by a white-box FGSM attack on the provided network.
    """
    adv_images = list()
    for x, y in dataloader:
        adv_images.append(fast_gradient_method(model, x, eps, np.inf).detach().numpy())
            
    adv_images = np.concatenate(adv_images)
    
    return adv_images
    

def one_vs_all_dataloader(data, labels, digit):
    """ Returns dataloader with labels modified so that samples belonging to the specified class have a 
        label of 1, and all other samples have a label of 0. Also returns an ndarray of modified labels
    """
    one_v_all_labels = np.zeros(labels.shape, dtype=labels.dtype)
    
    current_digit_idx = np.where(labels == digit)
    one_v_all_labels[current_digit_idx] = 1
    
    dataset = torch.utils.data.TensorDataset(torch.Tensor(data), torch.Tensor(labels).type(torch.long))
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)
    
    return dataloader, labels

def view_classify(img, ps, img_title=None):
    ''' Function for viewing an image and it's predicted classes.
    '''
    ps = ps.data.numpy().squeeze()

    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)
    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())
    ax1.axis('off')
    if img_title is not None:
        ax1.set_title(img_title)
    ax2.barh(np.arange(10), ps)
    ax2.set_aspect(0.1)
    ax2.set_yticks(np.arange(10))
    ax2.set_yticklabels(np.arange(10))
    ax2.set_title('Class Probability')
    ax2.set_xlim(0, 1.1)
    plt.tight_layout()